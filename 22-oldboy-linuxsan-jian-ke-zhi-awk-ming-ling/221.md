#### 1、awk简介

awk不仅是linux系统中的一个命令，而且是一种编程语言，可以用来处理数据和生成报告（excel）。处理的数据可以是一个或多个文件，可以是来自标准输入，也可以通过管道获取输入，awk可以在命令行上直接编辑命令进行操作，也可以编写成awk程序来进行更为复杂的运用

#### 2、awk工作原理

![](https://www.luffycity.com/linux-book/assets/21-1.png)

##### awk 'BEGIN{ commands } pattern{ commands } END{ commands }' {#awk--begin-commands--pattern-commands--end-commands-}

第一步：执行BEGIN{ commands }语句块中的语句；

第二步：从文件或标准输入\(stdin\)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。

第三步：当读至输入流末尾时，执行END{ commands }语句块。

BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。

END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。

pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。

示例

echo -e "A line 1nA line 2" \| awk 'BEGIN{ print "Start" } { print } END{ print "End" }'

Start

A line 1

A line 2

End

当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。在awk的print语句块中双引号是被当作拼接符使用，例如：

echo \| awk '{ var1="v1"; var2="v2"; var3="v3"; print var1,var2,var3; }'

v1 v2 v3

双引号拼接使用：

echo \| awk '{ var1="v1"; var2="v2"; var3="v3"; print var1"="var2"="var3; }'

v1=v2=v3

{ }类似一个循环体，会对文件中的每一行进行迭代，通常变量初始化语句（如：i=0）以及打印文件头部的语句放入BEGIN语句块中，将打印的结果等语句放在END语句块中。

#### 3、awk版本

\[root@nfsserver ~\]\# cat /etc/redhat-release

CentOS release 6.7 \(Final\)

\[root@nfsserver ~\]\# uname -r

2.6.32-573.el6.x86\_64

\[root@nfsserver ~\]\# ll \`which awk\`

lrwxrwxrwx. 1 root root 4 3月 6 16:24 /bin/awk -&gt; gawk

\[root@nfsserver ~\]\# awk --version

GNU Awk 3.1.7

### 4、awk 格式 {#14---awk-格式}

awk指令是由模式，动作，或者模式和动作的组合组成。

模式（pattern）,可以由表达式组成，也可以是两个 / 之间的正则表达式 比如 NR==1，这就是模式，可以把它理解为一个条件

动作（action）， 是由在大括号里面的一条或多条语句组成，语句之间使用 ; 隔开，格式如下

![](https://www.luffycity.com/linux-book/assets/21-2.png)

awk处理的内容可以来自标准输入 、管道、 文件

##### 例子：

```
awk -F ":" 'NR>=2 && NR<=6{print NR,$1}' /etc/passwd
2 bin
3 daemon
4 adm
5 lp
6 sync
```

#### 5、awk执行过程

![](https://www.luffycity.com/linux-book/assets/21-3.png)

awk是通过一行一行的处理文件，这条命令中包含模式部分（条件）和动作部分（动作），awk将处理模式（条件）指定的行

1）awk读入第一行内容

2）判断是否符合模式中的条件

* 如果匹配则执行对应的动作
* 如果不匹配条件，继续读取下一行

3）继续读取下一行

4）重复1-3，直到读取到最后一行

1、命令行的赋值（-F 或 -v）

2、执行BEGIN模式里面的内容

3、开始读取文件

4、判断条件（模式）是否成立

成立则执行对应动作里面的内容

读取下一行，循环判断

直到读取到最后一个文件的结尾

5、最后执行END模式里面的内容

6、结束

\[root@nfsserver files\]\# awk -F ":" 'NR==1{print NR,$0}NR==2{print NR,$NF"second line"}' awkfile.txt

1 root:x:0:0:root:/root:/bin/bash

2 /sbin/nologinsecond line

#### 6、字段（列）和记录（行）

![](/assets/22-41.png)

##### 1）域（区域，列）

每条记录都是由多个字段组成的，默认情况下字段之间的分隔符是由空格（空格或制表符）

来分隔，并且将分隔符记录在内置变量FS中，每行记录的字段数保存在awk的内置变量NF中

$1（第一字段）,$2（第二字段）,$3（第三字段）,$NF（最后一个字段）

$0（整行），一个记录

$ 表示取，引用某个列（区域）

FS filed separator 区域分隔符 awk内置变量 awk -F 就是改变 FS 的值

NF number of fileds 列的数量一行有多少列（区域）

##### 创建环境

```
mkdir /server/files/ -p
head /etc/passwd > /server/files/awkfile.txt
cat /server/files/awkfile.txt
[root@nfsserver ~]# cat /server/files/awkfile.txt
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
```

```
[root@nfsserver ~]# awk 'NR>=2{print $0}' /server/files/awkfile.txt
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
[root@nfsserver ~]# awk -F ":" 'NR>=2&&NR<=5{print $1,$3}' /server/files/awkfile.txt
bin 1
daemon 2
adm 3
lp 4
```

#### 2）记录（行）分隔符-RS

awk对每个要处理的输入数据认为都是具有格式和结构的，而不仅仅是一堆字符串。

默认情况下，每一行内容都成为一条记录，并以换行符结束

i、默认情况 一行 &lt;==&gt; 一个记录， 每行，都是一个记录

ii、RS ==&gt; record separator 输入记录（行）分隔符

iii、NR ==&gt; number of record 行号，记录的数 awk当前处理着的，记录的数

iv、ORS ==&gt; output record separator 输出时候的分隔符

awk使用内置变量RS来存放记录分隔符，RS表示的是输入的记录分隔符，这个值可以通过

BEGIN模块重新定义修改 在awk执行之前执行

```
[root@nfsserver ~]# awk '{print NR,$0}' /server/files/awkfile.txt
1 root:x:0:0:root:/root:/bin/bash
2 bin:x:1:1:bin:/bin:/sbin/nologin
3 daemon:x:2:2:daemon:/sbin:/sbin/nologin
4 adm:x:3:4:adm:/var/adm:/sbin/nologin
5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
6 sync:x:5:0:sync:/sbin:/bin/sync
7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
8 halt:x:7:0:halt:/sbin:/sbin/halt
9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
10 uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
[root@nfsserver ~]# awk 'BEGIN{RS="/"}{print NR,$0}' /server/files/awkfile.txt
1 root:x:0:0:root:
2 root:
3 bin
4 bash
bin:x:1:1:bin:
5 bin:
6 sbin
7 nologin
daemon:x:2:2:daemon:
8 sbin:
9 sbin
10 nologin
adm:x:3:4:adm:
11 var
12 adm:
13 sbin
14 nologin
lp:x:4:7:lp:
15 var
16 spool
17 lpd:
18 sbin
19 nologin
sync:x:5:0:sync:
20 sbin:
21 bin
22 sync
shutdown:x:6:0:shutdown:
23 sbin:
24 sbin
25 shutdown
halt:x:7:0:halt:
26 sbin:
27 sbin
28 halt
mail:x:8:12:mail:
29 var
30 spool
31 mail:
32 sbin
33 nologin
uucp:x:10:14:uucp:
34 var
35 spool
36 uucp:
37 sbin
38 nologin
```

#### 3）-v设置变量

```
awk -v RS="[0-9]+" '{print NR,$0}' awkfile.txt
1 root:x:
2 :
3 :root:/root:/bin/bash
bin:x:
4 :
5 :bin:/bin:/sbin/nologin
daemon:x:
6 :
7 :daemon:/sbin:/sbin/nologin
adm:x:
8 :
9 :adm:/var/adm:/sbin/nologin
lp:x:
10 :
11 :lp:/var/spool/lpd:/sbin/nologin
sync:x:
12 :
13 :sync:/sbin:/bin/sync
shutdown:x:
14 :
15 :shutdown:/sbin:/sbin/shutdown
halt:x:
16 :
17 :halt:/sbin:/sbin/halt
mail:x:
18 :
19 :mail:/var/spool/mail:/sbin/nologin
uucp:x:
20 :
21 :uucp:/var/spool/uucp:/sbin/nologin
```

说明：

在行首打印输出记录号，并打印出每一行$0的内容

awk眼中的文件是从头到尾一段连续的字符串，恰巧中间有些\n\(回车换行符\)，\n也是字符

为了方便人们的理解，awk默认就是把RS的值设置为 \n

```
[root@nfsserver ~]# awk 'BEGIN{RS=""}{print NR,$0}' /server/files/awkfile.txt
1 root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
```

#### 6、企业案例：计算文件中每个单词的重复数量

##### 环境

```
[root@nfsserver files]# sed -r 's#[:/0-9]+# #g' awkfile.txt >count.txt
[root@nfsserver files]# cat count.txt
root x root root bin bash
bin x bin bin sbin nologin
daemon x daemon sbin sbin nologin
adm x adm var adm sbin nologin
lp x lp var spool lpd sbin nologin
sync x sync sbin bin sync
shutdown x shutdown sbin sbin shutdown
halt x halt sbin sbin halt
mail x mail var spool mail sbin nologin
uucp x uucp var spool uucp sbin nologin
[root@oldboy files]# cat awkfile.txt
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin
```

方法一：

```
[root@oldboy files]# awk 'BEGIN{RS="[:/\n0-9]+"}{print $0}' awkfile.txt |sort |uniq -c|sort -nr
 12 sbin

 10 x

  6 nologin

  5 bin

  4 var

  3 uucp

  3 sync

  3 spool

  3 shutdown

  3 root

  3 mail

  3 halt

  3 adm

  2 lp

  2 daemon

  1 lpd

  1 bash
```

方法二：

```
[root@oldboy files]# egrep -o "[a-zA-Z]+" awkfile.txt |sort |uniq -c|sort -nr

12 sbin

10 x

6 nologin

5 bin

4 var

3 uucp

3 sync

3 spool

3 shutdown

3 root

3 mail

3 halt

3 adm

2 lp

2 daemon

1 lpd

1 bash
```

方法三：

```
[root@oldboy files]# awk 'BEGIN{RS="[^a-zA-Z]+"}{print $0}' awkfile.txt |sort |uniq -c|sort -nr
12 sbin

10 x

6 nologin

5 bin

4 var

3 uucp

3 sync

3 spool

3 shutdown

3 root

3 mail

3 halt

3 adm

2 lp

2 daemon

1 lpd

1 bash
```

方法四：

```
[root@nfsserver files]# awk 'BEGIN{RS="( )|\n"}{print $0}' count.txt |sort |uniq -c |sort -rnk1
12 sbin

10 x

6 nologin

5 bin

4 var

3 uucp

3 sync

3 spool

3 shutdown

3 root

3 mail

3 halt

3 adm

2 lp

2 daemon

1 lpd

1 bash
```

方法五：

```
[root@oldboy files]# awk -v RS='[:/0-9\n]+' '{print $0}' awkfile.txt |sort |uniq -c|sort -rn
12 sbin

10 x

6 nologin

5 bin

4 var

3 uucp

3 sync

3 spool

3 shutdown

3 root

3 mail

3 halt

3 adm

2 lp

2 daemon

1 lpd

1 bash
```

方法六：

```
[root@oldboy files]# awk -v RS='[^a-Z]+' '{print $0}' awkfile.txt |sort |uniq -c|sort -rn
12 sbin

10 x

6 nologin

5 bin

4 var

3 uucp

3 sync

3 spool

3 shutdown

3 root

3 mail

3 halt

3 adm

2 lp

2 daemon

1 lpd

1 bash
```

##### 小结

1）修改了RS的值，配合NR（行）来查看变化

2）修改了FS的值，配合NF（区域，列）

3）多使用，NR, NF, $数字，配合你调试你的awk命令

4）NR number of record 存放着每个记录的号（行号）读取新行时候会自动+1

5）RSrecoulseparator是输入数据的记录的分隔符，简单理解就是可以指定每个记录的结尾标志。

6）（用RS替换\n）

7）RS作用就是表示一个记录的结束。

8）FS标识着每个区域的结束。

#### 7、awk字段（列）分隔符-FS

FS 输入字段（列）分隔符

FS &lt;==&gt; -F

\[root@oldboy36 files\]\# awk -F ":" '{print $1}' awkfile.txt

root

bin

daemon

adm

lp

sync

shutdown

halt

mail

uucp

\[root@oldboy36 files\]\# awk 'BEGIN{FS=":"}{print $1}' awkfile.txt

root

bin

daemon

adm

lp

sync

shutdown

halt

mail

uucp

取ip

\[root@oldboy36 files\]\# ip a s eth0\|awk -F "\[ /\]+" 'NR==3{print $3}'

10.0.0.100

\[root@oldboy36 files\]\# ip a s eth0\|awk -F "\[^0-9.\]+" 'NR==3{print $2}'

10.0.0.100

\[root@oldboy files\]\# echo "I am oldboy,my qq is 31333741"&gt;&gt;/server/files/oldboy.txt

\[root@oldboy files\]\# cat oldboy.txt

I am oldboy,my qq is 31333741

\[root@oldboy files\]\# awk -F '\[ ,\]' '{print $3,$NF}' oldboy.txt

oldboy 31333741

#### 8、ORS与OFS

RS是输入记录分隔符，决定awk如何读取或分割每行（记录）

ORS表示输出记录分隔符（output record separator）,决定awk如何输出一行（记录）的，默认是回车换行 \n

FS是输入分隔符，决定awk读入一行后如何再分为多个区域

OFS表示输出分隔符，决定awk输出每个区域的时候使用什么分割

说明：

awk在输出整行即$0时，仅仅是原封不动的输出整行，没有任何修改，这就造成一个问题，如果我修改了OFS，那么输出整行的时候print $0  , 也不会有任何改变。

即：如果awk的action动作没有更改行的内容，OFS（包括ORS）都不会生效

所以我们需要让awk知道$0被修改了

$1=$1 把 $1 的值赋值给$1 这显然不会修改任何内容，但是这个动作会通知awk 我修改了$1的内容，所以再次修改print $0 时， $0的内容就变化了

\[root@oldboy32-vm1 files\]\# cat ors.txt

a

b

c

\[root@oldboy32-vm1 files\]\# awk 'BEGIN{ORS="oldboy"}{print $0}' ors.txt

aoldboyboldboyc

#### 9、字段（列）和记录（行）小结

1）$ 表示取字段（列）， $1，$2 NF，$NF

2）NF number of fileds 表示记录中的区域数量， $NF 取最后一个区域

3）FS \(-F\) filed separator 区域分隔符， awk -F ":" ===&gt; awk 'BEGIN{FS=":"}'

4）RS record sepatator 记录分隔符 （行的结束标识）

5）NR number of record 行号

6）选好合适的刀 FS（\*\*\*），RS， OFS, ORS

8）$1,$3,$数字 选中你要处理的区域

9） 分隔符==&gt;结束标识

10）记录与区域，你就对我们所谓的行与列，有了新的认识（RS，FS）

11）输入支持正则，输出不支持正则

#### 10、awk支持的关系运算符

运算符 含义 示例

&lt; 小于 x&lt;y

&lt;= 小于或等于 x&lt;=y

== 等于 x==y

!= 不等于 x!=y

&gt;= 大于或等于 x&gt;=y

&gt; 大于 x&gt;y

以上的运算符均是针对数字，下面两个运算符针对字符串

~ 与正则表达式匹配 x~/y/

!~ 与正则表达式不匹配 x!~y

awk把字符串认为是变量

\[root@db02 ~\]\# awk -F : '$5=="root"' passwd

root:x:0:0:root:/root:/bin/bash

#### 11、企业案例：取出常用服务端口号

ftp，http，https，mysql， ssh端口号

```
[root@nfsserver files]# awk -F "[ /]+" 'NR>100&&NR<120{print $2,$0}' /etc/services
unfortunately # unfortunately the poppassd (Eudora) uses a port which has already
been # been assigned to a different service. We list the poppassd as an
alias # alias here. This should work for programs asking for this service.
(due # (due to a bug in inetd the 3com-tsmux line is disabled)
106 #3com-tsmux 106/tcp poppassd
106 #3com-tsmux 106/udp poppassd
107 rtelnet 107/tcp # Remote Telnet
107 rtelnet 107/udp
109 pop2 109/tcp pop-2 postoffice # POP version 2
109 pop2 109/udp pop-2
110 pop3 110/tcp pop-3 # POP version 3
110 pop3 110/udp pop-3
111 sunrpc 111/tcp portmapper rpcbind # RPC 4.0 portmapper TCP
111 sunrpc 111/udp portmapper rpcbind # RPC 4.0 portmapper UDP
113 auth 113/tcp authentication tap ident
113 auth 113/udp authentication tap ident
115 sftp 115/tcp
115 sftp 115/udp
117 uucp-path 117/tcp
[root@nfsserver files]# awk -F "[ /]+" '$1~/^(ftp|http|https|mysql|ssh)$/{print $2,$0}' /etc/services
21 ftp 21/tcp
21 ftp 21/udp fsp fspd
22 ssh 22/tcp # The Secure Shell (SSH) Protocol
22 ssh 22/udp # The Secure Shell (SSH) Protocol
80 http 80/tcp www www-http # WorldWideWeb HTTP
80 http 80/udp www www-http # HyperText Transfer Protocol
80 http 80/sctp # HyperText Transfer Protocol
443 https 443/tcp # http protocol over TLS/SSL
443 https 443/udp # http protocol over TLS/SSL
443 https 443/sctp # http protocol over TLS/SSL
3306 mysql 3306/tcp # MySQL
3306 mysql 3306/udp # MySQL
21 ftp 21/sctp # FTP
22 ssh 22/sctp # SSH
[root@db02 ~]# awk -F "[ /]+" '$1~/^(ftp|http|https|mysql|ssh)$/{print $1,$2}' /etc/services |uniq
ftp 21
ssh 22
http 80
https 443
mysql 3306
ftp 21
ssh 22
```

#### 12、范围模式

awk '/start pos/,/end pos/{pint $0}' passwd

awk '/start pos/,NR==xxx{print $0}' passwd

范围模式的时候，范围条件的时候，表达式必须能匹配一行

\[root@nfsserver files\]\# sed -n '2,5p' count.txt

bin x bin bin sbin nologin

daemon x daemon sbin sbin nologin

adm x adm var adm sbin nologin

lp x lp var spool lpd sbin nologin

\[root@nfsserver files\]\# awk 'NR==2,NR==5{print NR,$0}' count.txt

2 bin x bin bin sbin nologin

3 daemon x daemon sbin sbin nologin

4 adm x adm var adm sbin nologin

5 lp x lp var spool lpd sbin nologin

\[root@nfsserver files\]\# sed -n '/^bin/,/^lp/p' count.txt

bin x bin bin sbin nologin

daemon x daemon sbin sbin nologin

adm x adm var adm sbin nologin

lp x lp var spool lpd sbin nologin

\[root@nfsserver files\]\# awk '/^bin/,/^lp/{print NR,$0}' count.txt

2 bin x bin bin sbin nologin

3 daemon x daemon sbin sbin nologin

4 adm x adm var adm sbin nologin

5 lp x lp var spool lpd sbin nologin

#### 总结

1、模式===&gt;条件

2、正则表达式

3、条件表达式（NR&gt;=2 NR==2）

4、范围表达式 \( NR==2，NR==5 /正则表达式-开始/，/正则结束/ \)

7、$1~/正则表达式-开始/,$3~/正则结束/

8、列，区域：FS 刀分隔符，FS区域分隔符

9、行，记录: RS 刀分隔符，RS记录分隔符

10、 FS====&gt; NF 区域，列的数量

11、 RS====&gt; NR 记录号，随着记录的增加 NR 自动+1

